{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from graph import process_dataset, transform, centrality\n",
    "from IPython.display import clear_output\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from hdc import hdv, bind, bundle, sbundle, ItemMemory, hdvw, hdva, cosim, hdvsc, zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphe -> graphHD (graph, vertices, dimensions)\n",
    "\n",
    "\n",
    "def encode_graphe(graph, vertices, dimensions):\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdv(dimensions)\n",
    "\n",
    "    # Es = zero(dimensions)\n",
    "    Es = []\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        v1 = vertices[edge[0]]\n",
    "        v2 = vertices[edge[1]]\n",
    "        # Es = bundle([Es, bind([vertices[edge[0]], vertices[edge[1]]])])\n",
    "        Es.append(bind([v1, v2]))\n",
    "\n",
    "    return bundle(Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphew -> vertices with hdw and edges (graph, vertices, base)\n",
    "\n",
    "\n",
    "def encode_graphew(graph, vertices, base):\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdvw(base, float(node))\n",
    "\n",
    "    Es = []\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        v1 = vertices[edge[0]]\n",
    "        v2 = vertices[edge[1]]\n",
    "        Es.append(bind([v1, v2]))\n",
    "\n",
    "    return bundle(Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphv -> vertices with hdv and no edges (graph, vertices, base)\n",
    "\n",
    "\n",
    "def encode_graphv(graph, vertices, dimensions):\n",
    "    Vs = []\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdv(dimensions)\n",
    "        Vs.append(vertices[node])\n",
    "\n",
    "    return bundle(Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphvw -> vertices with hdw and no edges (graph, vertices, base)\n",
    "\n",
    "\n",
    "def encode_graphvw(graph, vertices, base):\n",
    "    Vs = []\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdvw(base, float(node))\n",
    "        Vs.append(vertices[node])\n",
    "\n",
    "    return bundle(Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphvc -> vertices with hdvc and no edges (graph, vertices, vs)\n",
    "\n",
    "\n",
    "def encode_graphvc(graph, vertices, vs):  # [0-1] encoded into hvds with precision n\n",
    "    return bundle(map(lambda n: vs[round(float(n) * len(vs))], graph.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, encoder, transformer, step=20):\n",
    "        self.encoder = encoder\n",
    "        self.transformer = transformer\n",
    "        self.step = step\n",
    "        self.memory = ItemMemory()\n",
    "        self.vertices = dict()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        classes = {label: [] for label in set(y)}\n",
    "\n",
    "        for i, graph in enumerate(self.transformer(X)):\n",
    "            classes[y[i]].append(self.encoder(graph, self.vertices))\n",
    "\n",
    "        for key, value in classes.items():\n",
    "            for i in range(0, len(value), self.step):\n",
    "                H = bundle(value[i : i + self.step])\n",
    "                self.memory.add_vector(str(key), H)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        p = []\n",
    "        for query in self.transformer(X):\n",
    "            (label, _, _) = self.memory.cleanup(self.encoder(query, self.vertices))\n",
    "            p.append(int(label))\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = load_dataset(\"graphs-datasets/MUTAG\")[\"train\"]\n",
    "# DATASET = load_dataset(\"graphs-datasets/PROTEINS\")[\"train\"]\n",
    "# DATASET = load_dataset(\"graphs-datasets/AIDS\")[\"full\"]\n",
    "# DATASET = load_dataset(\"graphs-datasets/IMDB-BINARY\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(graphs, labels) = process_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS, REPS = 10, 3\n",
    "ALPHA, DIGITS, DIMENSIONS, STEP, N = 0.15, 4, 10000, 400, 1000\n",
    "CV = FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = hdvsc(N, DIMENSIONS, side=80, iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "\n",
    "\n",
    "encoders = {\n",
    "    \"graphe\": partial(encode_graphe, dimensions=DIMENSIONS),\n",
    "    \"graphew\": partial(encode_graphew, base=hdv(DIMENSIONS)),\n",
    "    \"graphv\": partial(encode_graphv, dimensions=DIMENSIONS),\n",
    "    \"graphvw\": partial(encode_graphvw, base=hdv(DIMENSIONS)),\n",
    "    # \"graphvc\": partial(encode_graphvc, vs=vs),\n",
    "}\n",
    "\n",
    "transformers = {\n",
    "    \"pagerank\": partial(centrality, rank=partial(nx.pagerank, alpha=ALPHA)),\n",
    "    \"degree_centrality\": partial(centrality, rank=partial(nx.degree_centrality)),\n",
    "    \"eigenvector_centrality_numpy\": partial(\n",
    "        centrality, rank=partial(nx.eigenvector_centrality_numpy)\n",
    "    ),\n",
    "    \"katz_centrality_numpy\": partial(\n",
    "        centrality, rank=partial(nx.katz_centrality_numpy)\n",
    "    ),\n",
    "    \"betweenness_centrality\": partial(\n",
    "        centrality, rank=partial(nx.betweenness_centrality)\n",
    "    ),\n",
    "    \"current_flow_closeness_centrality\": partial(\n",
    "        centrality, rank=partial(nx.current_flow_closeness_centrality)\n",
    "    ),\n",
    "    \"closeness_centrality\": partial(centrality, rank=partial(nx.closeness_centrality)),\n",
    "    \"edge_current_flow_betweenness_centrality\": partial(\n",
    "        centrality, rank=partial(nx.edge_current_flow_betweenness_centrality)\n",
    "    ),\n",
    "    \"laplacian_centrality\": partial(centrality, rank=partial(nx.laplacian_centrality)),\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    for tl, transformer in transformers.items():\n",
    "        print(tl)\n",
    "        esum = 0\n",
    "        for el, encoder in encoders.items():\n",
    "            clf = GraphClassifier(encoder, transformer, step=STEP)\n",
    "            sum = 0\n",
    "            start_time = time.time()\n",
    "            for i in range(REPS):\n",
    "                CV = ShuffleSplit()  # random_state=0\n",
    "                scores = cross_val_score(clf, graphs, labels, cv=CV, n_jobs=-1)\n",
    "                sum += scores.mean()\n",
    "                esum += scores.mean()\n",
    "                del scores\n",
    "            end_time = time.time()\n",
    "            print(\n",
    "                \"  Acc => %.5f\" % (sum / REPS),\n",
    "                \"T => %.5f\" % ((end_time - start_time) / REPS),\n",
    "                el,\n",
    "            )\n",
    "        print(\" Acc => %.5f\" % (esum / (REPS * len(encoders))))\n",
    "\n",
    "\n",
    "def predict():\n",
    "    for label, encoder in encoders.items():\n",
    "        clf = GraphClassifier(encoder, transformers[\"closeness_centrality\"], step=STEP)\n",
    "        clf.fit(graphs[:900], labels[:900])\n",
    "        # clear_output(wait=True)\n",
    "        print(accuracy_score(labels[900:], clf.predict(graphs[900:])), label)\n",
    "\n",
    "\n",
    "main()\n",
    "# predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "def similarity_heatmap(xs, targets, round=2, xlabel=None):\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1.0)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for n in range(len(targets)):\n",
    "        # plt.subplot(len(targets) * 2, 1, n + 2)\n",
    "        sims = []\n",
    "\n",
    "        for x in xs:\n",
    "            sims.append(cosim(targets[n], x))\n",
    "\n",
    "        # xaxis = [x + 0.5 for x in range(len(xs))]\n",
    "        # X_Y_Spline = make_interp_spline(xaxis, sims)\n",
    "        # plt.xticks([]), plt.yticks([])\n",
    "        # plt.xlim(xmin=0, xmax=len(xs))\n",
    "        # X_ = np.linspace(0, len(xs), len(xs) * 16 * 2)\n",
    "        # Y_ = X_Y_Spline(X_)\n",
    "        # plt.plot(X_, Y_, linewidth=1)\n",
    "\n",
    "        plt.subplot(len(targets) * 2, 1, n + 1)\n",
    "        plt.yticks([]), plt.xticks([])\n",
    "        plt.pcolormesh([sims] * 1, cmap=\"plasma\", norm=norm)\n",
    "        if round >= 0:\n",
    "            for i in range(len(xs)):\n",
    "                plt.text(\n",
    "                    i + 0.5,\n",
    "                    0 + 0.5,\n",
    "                    f\"%.{round}f\" % sims[i],\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    rotation=\"vertical\",\n",
    "                    **{\"fontname\": \"JetBrains Mono\", \"fontsize\": 12},\n",
    "                )\n",
    "        if xlabel:\n",
    "            plt.xlabel(xlabel, **{\"fontname\": \"JetBrains Mono\", \"fontsize\": 12})\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "similarity_heatmap(vs[:50], [vs[5]], round=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs0 = hdvsc(10, DIMENSIONS, side=2, iter=1, weight=0)\n",
    "similarity_heatmap(vs0, [vs0[6]], round=4, xlabel=\"iter=1 • side=2 • weight=0\")\n",
    "\n",
    "vs0 = hdvsc(10, DIMENSIONS, side=2, iter=2, weight=0)\n",
    "similarity_heatmap(vs0, [vs0[6]], round=4, xlabel=\"iter=2 • side=2 • weight=0\")\n",
    "\n",
    "vs0 = hdvsc(10, DIMENSIONS, side=2, iter=4, weight=0)\n",
    "similarity_heatmap(vs0, [vs0[6]], round=4, xlabel=\"iter=4 • side=2 • weight=0\")\n",
    "\n",
    "vs0 = hdvsc(10, DIMENSIONS, side=6, iter=1, weight=0)\n",
    "similarity_heatmap(vs0, [vs0[6]], round=4, xlabel=\"iter=1 • side=6 • weight=0\")\n",
    "\n",
    "vs0 = hdvsc(10, DIMENSIONS, side=6, iter=1, weight=2)\n",
    "similarity_heatmap(vs0, [vs0[6]], round=4, xlabel=\"iter=1 • side=6 • weight=2\")\n",
    "\n",
    "vs0 = hdvsc(10, DIMENSIONS, side=6, iter=1, weight=4)\n",
    "similarity_heatmap(vs0, [vs0[6]], round=4, xlabel=\"iter=1 • side=6 • weight=4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
