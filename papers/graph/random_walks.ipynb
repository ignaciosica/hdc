{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, cross_val_predict\n",
    "from graph import process_dataset\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import thdc\n",
    "from hdc import pm\n",
    "\n",
    "\n",
    "torch.set_default_device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = load_dataset(\"graphs-datasets/MUTAG\")[\"train\"]\n",
    "# DATASET = load_dataset(\"graphs-datasets/AIDS\")[\"full\"]\n",
    "# DATASET = load_dataset(\"graphs-datasets/PROTEINS\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(length):\n",
    "    m = {}\n",
    "    a = random.sample(range(length), length)\n",
    "    for i in range(length):\n",
    "        m[i] = a[i]\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 2000\n",
    "(graphs, labels) = process_dataset(DATASET)\n",
    "VECTORS = torch.randint(0, 2, (30, DIMENSIONS), dtype=torch.float64).cuda()\n",
    "VECTORS[VECTORS == 0] = -1\n",
    "\n",
    "MAT = torch.from_numpy(pm(DIMENSIONS)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(graph, vectors, mat):\n",
    "    # g = graph\n",
    "    g = nx.relabel_nodes(graph, create_map(len(list(graph))))\n",
    "    # g = nx.relabel_nodes(graph, create_map(30))\n",
    "    G = None\n",
    "    for n in random.sample(list(g), 4):\n",
    "        # for vs in nx.bfs_layers(g, [0]):\n",
    "        for vs in nx.dfs_preorder_nodes(g, n):\n",
    "            # for vs in nx.bfs_layers(g, [list(g)[0]]):\n",
    "            # for vs in nx.bfs_layers(g, [n]):\n",
    "            # for vs in nx.bfs_layers(g, [list(g)]):\n",
    "            if G is None:\n",
    "                G = torch.sum(\n",
    "                    torch.index_select(vectors, 0, torch.tensor(vs)),\n",
    "                    dim=0,\n",
    "                )\n",
    "            else:\n",
    "                G = torch.sum(\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            torch.matmul(G, mat)[None, :],\n",
    "                            torch.index_select(vectors, 0, torch.tensor(vs)),\n",
    "                        ],\n",
    "                        0,\n",
    "                    ),\n",
    "                    dim=0,\n",
    "                )\n",
    "        yield G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.memory = thdc.ItemMemory()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in range(len(X)):\n",
    "            for x in encode(X[i], VECTORS, MAT):\n",
    "                self.memory.add_vector(y[i], x)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        p = []\n",
    "        for query in X:\n",
    "            max_score = 0\n",
    "\n",
    "            for x in encode(query, VECTORS, MAT):\n",
    "                # p.append(self.memory.cleanup(x)[0])\n",
    "                vs = self.memory.cleanup_all(x, 5)\n",
    "                s = sum(1 * v[2] ** 4 if v[0] == 1 else -1 * v[2] ** 4 for v in vs)\n",
    "                if abs(s) > max_score:\n",
    "                    max_score = s\n",
    "\n",
    "            p.append(1 if max_score >= 0 else 0)\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.789) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.789) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.789) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.895) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.684) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.579) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.789) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.737) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.632) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.737) total time=   1.3s\n",
      "Acc => 0.7421052631578947\n",
      "[CV] END ................................ score: (test=0.842) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.842) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.579) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.579) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.684) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.842) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.632) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.842) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.895) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.579) total time=   1.3s\n",
      "Acc => 0.7315789473684211\n",
      "[CV] END ................................ score: (test=0.684) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.579) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.684) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.632) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.789) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.737) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.737) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.737) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.632) total time=   1.3s\n",
      "[CV] END ................................ score: (test=0.632) total time=   1.3s\n",
      "Acc => 0.6842105263157896\n",
      "Avg Acc => 0.7192982456140351\n"
     ]
    }
   ],
   "source": [
    "FOLDS, REPS = 10, 3\n",
    "\n",
    "\n",
    "def main():\n",
    "    sum = 0\n",
    "    for _ in range(REPS):\n",
    "        clf = GraphClassifier()\n",
    "        scores = cross_val_score(\n",
    "            clf,\n",
    "            graphs,\n",
    "            labels,\n",
    "            cv=ShuffleSplit(n_splits=FOLDS),\n",
    "            n_jobs=1,\n",
    "            verbose=4,\n",
    "        )\n",
    "        print(\"Acc =>\", scores.mean())\n",
    "        sum += scores.mean()\n",
    "    print(\"Avg Acc =>\", sum / REPS)\n",
    "\n",
    "\n",
    "def conf():\n",
    "    clf = GraphClassifier()\n",
    "    y_pred = cross_val_predict(clf, graphs, labels, cv=FOLDS, n_jobs=1)\n",
    "    print(confusion_matrix(labels, y_pred))\n",
    "    print(accuracy_score(labels, y_pred))\n",
    "\n",
    "\n",
    "main()\n",
    "# conf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
