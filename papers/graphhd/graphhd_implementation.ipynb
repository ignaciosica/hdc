{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS_full.zip\n",
      "Extracting ../data/PROTEINS_full/PROTEINS_full.zip\n",
      "Processing...\n",
      "Done!\n",
      "Testing 30 times: 100%|██████████| 30/30 [02:11<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PROTEINS_full\n",
      "GraphHD: accuracy of 68.214% with std 2.106%\n",
      "Test: accuracy of 68.902% with std 2.041%\n",
      "Comparison between predictions: 94.002% with std 1.274%\n",
      "Time: 4.366s with std 0.097s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing 30 times: 100%|██████████| 30/30 [00:23<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: accuracy of 68.837% with std 2.231%\n",
      "Time: 0.791s with std 0.033s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "# Note: this example requires the torch_geometric library: https://pytorch-geometric.readthedocs.io\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "\n",
    "import torchhd\n",
    "from torchhd import embeddings\n",
    "from torchhd.models import Centroid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "DIMENSIONS = 10000  # hypervectors dimension\n",
    "\n",
    "# for other available datasets see: https://pytorch-geometric.readthedocs.io/en/latest/notes/data_cheatsheet.html?highlight=tudatasets\n",
    "dataset = \"PROTEINS_full\"\n",
    "\n",
    "graphs = TUDataset(\"../data\", dataset)\n",
    "train_size = int(0.7 * len(graphs))\n",
    "test_size = len(graphs) - train_size\n",
    "\n",
    "\n",
    "def sparse_stochastic_graph(G):\n",
    "    \"\"\"\n",
    "    Returns a sparse adjacency matrix of the graph G.\n",
    "    The values indicate the probability of leaving a vertex.\n",
    "    This means that each column sums up to one.\n",
    "    \"\"\"\n",
    "    _, columns = G.edge_index\n",
    "    # Calculate the probability for each column\n",
    "    values_per_column = 1.0 / torch.bincount(columns, minlength=G.num_nodes)\n",
    "    values_per_node = values_per_column[columns]\n",
    "    size = (G.num_nodes, G.num_nodes)\n",
    "    return torch.sparse_coo_tensor(G.edge_index, values_per_node, size)\n",
    "\n",
    "\n",
    "def pagerank(G, alpha=0.45, max_iter=100, tol=1e-06):\n",
    "    N = G.num_nodes\n",
    "    M = sparse_stochastic_graph(G) * alpha\n",
    "    v = torch.zeros(N, device=G.edge_index.device) + 1 / N\n",
    "    p = torch.zeros(N, device=G.edge_index.device) + 1 / N\n",
    "    for _ in range(max_iter):\n",
    "        v_prev = v\n",
    "        v = M @ v + p * (1 - alpha)\n",
    "\n",
    "        err = (v - v_prev).abs().sum()\n",
    "        if tol != None and err < N * tol:\n",
    "            return v\n",
    "    return v\n",
    "\n",
    "\n",
    "def degree_centrality(G):\n",
    "    \"\"\"\n",
    "    Compute the degree centrality for nodes.\n",
    "    \"\"\"\n",
    "    _, columns = G.edge_index\n",
    "    degree = torch.bincount(columns, minlength=G.num_nodes)\n",
    "    return degree / G.num_nodes\n",
    "\n",
    "\n",
    "def to_undirected(edge_index):\n",
    "    \"\"\"\n",
    "    Returns the undirected edge_index\n",
    "    [[0, 1], [1, 0]] will result in [[0], [1]]\n",
    "    \"\"\"\n",
    "    edge_index = edge_index.sort(dim=0)[0]\n",
    "    edge_index = torch.unique(edge_index, dim=1)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def min_max_graph_size(graph_dataset):\n",
    "    if len(graph_dataset) == 0:\n",
    "        return None, None\n",
    "\n",
    "    max_num_nodes = float(\"-inf\")\n",
    "    min_num_nodes = float(\"inf\")\n",
    "\n",
    "    for G in graph_dataset:\n",
    "        num_nodes = G.num_nodes\n",
    "        max_num_nodes = max(max_num_nodes, num_nodes)\n",
    "        min_num_nodes = min(min_num_nodes, num_nodes)\n",
    "\n",
    "    return min_num_nodes, max_num_nodes\n",
    "\n",
    "\n",
    "class Default(nn.Module):\n",
    "    def __init__(self, out_features, size):\n",
    "        super(Default, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.node_ids = embeddings.Random(size, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pr = pagerank(x)\n",
    "        _, pr_argsort = pr.sort()\n",
    "\n",
    "        node_id_hvs = torch.zeros((x.num_nodes, self.out_features), device=device)\n",
    "        node_id_hvs[pr_argsort] = self.node_ids.weight[: x.num_nodes]\n",
    "\n",
    "        row, col = to_undirected(x.edge_index)\n",
    "\n",
    "        hvs = torchhd.bind(node_id_hvs[row], node_id_hvs[col])\n",
    "        return torchhd.multiset(hvs)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_features, size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        # self.node_ids = embeddings.Level(size, out_features, sparse=True)\n",
    "        self.node_ids = embeddings.Random(size, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pr = pagerank(x)\n",
    "        pr = degree_centrality(x)\n",
    "        sort, pr_argsort = pr.sort()\n",
    "        # pr_argsort = [i for i in range(x.num_nodes)]\n",
    "        # print(sort)\n",
    "\n",
    "        node_id_hvs = torch.zeros((x.num_nodes, self.out_features), device=device)\n",
    "        # node_id_hvs[pr_argsort] = self.node_ids(sort)\n",
    "        node_id_hvs[pr_argsort] = self.node_ids.weight[: x.num_nodes]\n",
    "\n",
    "        row, col = to_undirected(x.edge_index)\n",
    "\n",
    "        hvs = torchhd.bind(node_id_hvs[row], node_id_hvs[col])\n",
    "        return torchhd.multiset(hvs)\n",
    "\n",
    "        return torchhd.multiset(node_id_hvs)\n",
    "\n",
    "\n",
    "default_acc = []\n",
    "test_acc = []\n",
    "comparison_acc = []\n",
    "iters = 30\n",
    "\n",
    "min_graph_size, max_graph_size = min_max_graph_size(graphs)\n",
    "default_encoder = Default(DIMENSIONS, max_graph_size)\n",
    "default_encoder = default_encoder.to(device)\n",
    "\n",
    "test_encoder = Encoder(DIMENSIONS, max_graph_size)\n",
    "test_encoder = test_encoder.to(device)\n",
    "\n",
    "time_acc = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(iters), desc=f\"Testing {iters} times\"):\n",
    "    start = time.time()\n",
    "\n",
    "    train_ld, test_ld = torch.utils.data.random_split(graphs, [train_size, test_size])\n",
    "\n",
    "    default_model = Centroid(DIMENSIONS, graphs.num_classes)\n",
    "    default_model = default_model.to(device)\n",
    "\n",
    "    test_model = Centroid(DIMENSIONS, graphs.num_classes)\n",
    "    test_model = test_model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for samples in tqdm(train_ld, desc=\"Training\", disable=True):\n",
    "            samples.edge_index = samples.edge_index.to(device)\n",
    "            samples.y = samples.y.to(device)\n",
    "\n",
    "            default_samples_hv = default_encoder(samples).unsqueeze(0)\n",
    "            default_model.add(default_samples_hv, samples.y)\n",
    "\n",
    "            test_samples_hv = test_encoder(samples).unsqueeze(0)\n",
    "            test_model.add(test_samples_hv, samples.y)\n",
    "\n",
    "    default_accuracy = torchmetrics.F1Score(\"multiclass\", num_classes=graphs.num_classes)\n",
    "    test_accuracy = torchmetrics.F1Score(\"multiclass\", num_classes=graphs.num_classes)\n",
    "    comparison_accuracy = torchmetrics.F1Score(\"multiclass\", num_classes=graphs.num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        default_model.normalize()\n",
    "        test_model.normalize()\n",
    "\n",
    "        for index, samples in enumerate(tqdm(test_ld, desc=\"Testing_\", disable=True)):\n",
    "            samples.edge_index = samples.edge_index.to(device)\n",
    "\n",
    "            default_samples_hv = default_encoder(samples).unsqueeze(0)\n",
    "            default_outputs = default_model(default_samples_hv, dot=True)\n",
    "\n",
    "            test_samples_hv = test_encoder(samples).unsqueeze(0)\n",
    "            test_outputs = test_model(test_samples_hv, dot=True)\n",
    "\n",
    "            default_accuracy.update(default_outputs.cpu(), samples.y)\n",
    "            test_accuracy.update(test_outputs.cpu(), samples.y)\n",
    "            comparison_accuracy.update(\n",
    "                torch.argmax(test_outputs, dim=-1).cpu(), torch.argmax(default_outputs, dim=-1).cpu()\n",
    "            )\n",
    "\n",
    "    default_acc.append(default_accuracy.compute().item() * 100)\n",
    "    test_acc.append(test_accuracy.compute().item() * 100)\n",
    "    comparison_acc.append(comparison_accuracy.compute().item() * 100)\n",
    "    end = time.time()\n",
    "    time_acc.append(end - start)\n",
    "\n",
    "print(f\"Testing {dataset}\")\n",
    "print(f\"GraphHD: accuracy of {(np.mean(default_acc)):.3f}% with std {(np.std(default_acc)):.3f}%\")\n",
    "print(f\"Test: accuracy of {(np.mean(test_acc)):.3f}% with std {(np.std(test_acc)):.3f}%\")\n",
    "print(f\"Comparison between predictions: {(np.mean(comparison_acc)):.3f}% with std {(np.std(comparison_acc)):.3f}%\")\n",
    "print(f\"Time: {(np.mean(time_acc)):.3f}s with std {(np.std(time_acc)):.3f}s\")\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "iters = 30\n",
    "time_acc = []\n",
    "\n",
    "for i in tqdm(range(iters), desc=f\"Testing {iters} times\"):\n",
    "    start = time.time()\n",
    "\n",
    "    train_ld, test_ld = torch.utils.data.random_split(graphs, [train_size, test_size])\n",
    "\n",
    "    test_model = Centroid(DIMENSIONS, graphs.num_classes)\n",
    "    test_model = test_model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for samples in tqdm(train_ld, desc=\"Training\", disable=True):\n",
    "            samples.edge_index = samples.edge_index.to(device)\n",
    "            samples.y = samples.y.to(device)\n",
    "\n",
    "            test_samples_hv = test_encoder(samples).unsqueeze(0)\n",
    "            test_model.add(test_samples_hv, samples.y)\n",
    "\n",
    "    test_accuracy = torchmetrics.F1Score(\"multiclass\", num_classes=graphs.num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_model.normalize()\n",
    "\n",
    "        for index, samples in enumerate(tqdm(test_ld, desc=\"Testing_\", disable=True)):\n",
    "            samples.edge_index = samples.edge_index.to(device)\n",
    "\n",
    "            test_samples_hv = test_encoder(samples).unsqueeze(0)\n",
    "            test_outputs = test_model(test_samples_hv, dot=True)\n",
    "\n",
    "            test_accuracy.update(test_outputs.cpu(), samples.y)\n",
    "\n",
    "    test_acc.append(test_accuracy.compute().item() * 100)\n",
    "    end = time.time()\n",
    "    time_acc.append(end - start)\n",
    "\n",
    "print(f\"Test: accuracy of {(np.mean(test_acc)):.3f}% with std {(np.std(test_acc)):.3f}%\")\n",
    "print(f\"Time: {(np.mean(time_acc)):.3f}s with std {(np.std(time_acc)):.3f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
