{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "from graph import process_dataset, transform\n",
    "from hdc import hdv, bind, bundle, sbundle, ItemMemory, hdvw, hdva, cosim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graph -> graphHD (graph, vertices, dimensions)\n",
    "\n",
    "\n",
    "def encode_graph(graph, vertices, dimensions):\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdv(dimensions)\n",
    "\n",
    "    Es = []\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        v1 = vertices[edge[0]]\n",
    "        v2 = vertices[edge[1]]\n",
    "        E = bind([v1, v2])\n",
    "        Es.append(E)\n",
    "\n",
    "    return bundle(Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphw -> vertices with hdw and edges (graph, vertices, base)\n",
    "\n",
    "\n",
    "def encode_graphw(graph, vertices, base):\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdvw(base, float(node))\n",
    "\n",
    "    Es = []\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        v1 = vertices[edge[0]]\n",
    "        v2 = vertices[edge[1]]\n",
    "        E = bind([v1, v2])\n",
    "        Es.append(E)\n",
    "\n",
    "    return bundle(Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphv -> vertices with hdv and no edges (graph, vertices, base)\n",
    "\n",
    "\n",
    "def encode_graphv(graph, vertices, base):\n",
    "    Vs = []\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdvw(base, float(node))\n",
    "        Vs.append(vertices[node])\n",
    "\n",
    "    return bundle(Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_graphvw -> vertices with hdw and no edges (graph, vertices, base)\n",
    "\n",
    "\n",
    "def encode_graphvw(graph, vertices, base):\n",
    "    Vs = []\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdvw(base, float(node))\n",
    "        Vs.append(vertices[node])\n",
    "\n",
    "    return bundle(Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEstimator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, encoder, alpha=0.45, digits=4, step=20):\n",
    "        self.encoder = encoder\n",
    "        self.alpha = alpha\n",
    "        self.digits = digits\n",
    "        self.step = step\n",
    "        self.memory = ItemMemory()\n",
    "        self.vertices = dict()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        classes = {label: [] for label in set(y)}\n",
    "        graphs = transform(X, self.alpha, self.digits)\n",
    "\n",
    "        for i in range(len(graphs)):\n",
    "            G = self.encoder(graphs[i], self.vertices)\n",
    "            classes[y[i]].append(G)\n",
    "\n",
    "        for key, value in classes.items():\n",
    "            for i in range(0, len(value), self.step):\n",
    "                H = bundle(value[i : i + self.step])\n",
    "                self.memory.add_vector(str(key), H)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        p, s, queries = [], [], transform(X, self.alpha, self.digits)\n",
    "\n",
    "        for query in queries:\n",
    "            query_vector = self.encoder(query, self.vertices)\n",
    "            (label, _, _) = self.memory.cleanup(query_vector)\n",
    "\n",
    "            p.append(int(label))\n",
    "            # s.append(cosine_similarity(queryVector, cleanVector[1]))\n",
    "\n",
    "        # print(\"%.5f\" % round(np.mean(s), 5), \"0:\", p.count(0), \"1:\", p.count(1))\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUTAG = load_dataset(\"graphs-datasets/MUTAG\")[\"train\"]\n",
    "# PROTEINS = load_dataset(\"graphs-datasets/PROTEINS\")[\"train\"]\n",
    "# AIDS = load_dataset(\"graphs-datasets/AIDS\")[\"full\"]\n",
    "# IMDB = load_dataset(\"graphs-datasets/IMDB-BINARY\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(graphs, labels) = process_dataset(MUTAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S => 0.83053 T => 0.44938\n",
      "S => 0.85368 T => 0.41567\n",
      "S => 0.82421 T => 0.42785\n",
      "S => 0.82947 T => 0.40381\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import time\n",
    "\n",
    "FOLDS, REPS = 10, 5\n",
    "ALPHA, DIGITS, DIMENSIONS, STEP = 0.65, 2, 10000, 4\n",
    "CV = FOLDS\n",
    "\n",
    "encoders = [\n",
    "    partial(encode_graph, dimensions=DIMENSIONS),\n",
    "    partial(encode_graphv, base=hdv(DIMENSIONS)),\n",
    "    partial(encode_graphw, base=hdv(DIMENSIONS)),\n",
    "    partial(encode_graphvw, base=hdv(DIMENSIONS)),\n",
    "]\n",
    "\n",
    "\n",
    "def main():\n",
    "    for encoder in encoders:\n",
    "        clf = GraphEstimator(encoder, alpha=ALPHA, digits=DIGITS, step=STEP)\n",
    "        sum = 0\n",
    "        start_time = time.time()\n",
    "        for i in range(REPS):\n",
    "            CV = ShuffleSplit()  # random_state=0\n",
    "            scores = cross_val_score(\n",
    "                clf, graphs, labels, n_jobs=-1, cv=CV, verbose=0, error_score=\"raise\"\n",
    "            )\n",
    "            sum += scores.mean()\n",
    "            del scores\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            \"S => %.5f\" % (sum / REPS),\n",
    "            \"T => %.5f\" % ((end_time - start_time) / REPS),\n",
    "        )\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
