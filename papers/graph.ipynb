{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "import networkx as nx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithemitic operations\n",
    "\n",
    "\n",
    "def hdv(d):\n",
    "    return np.random.choice([-1, 1], d)\n",
    "\n",
    "\n",
    "def bind(xs):\n",
    "    return ft.reduce(lambda x, y: x * y, xs)\n",
    "\n",
    "\n",
    "def bundle(xs):\n",
    "    return ft.reduce(lambda x, y: x + y, xs)\n",
    "\n",
    "\n",
    "def similarity(A, B):\n",
    "    return np.dot(A, B) / len(A)\n",
    "\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_A = np.linalg.norm(A)\n",
    "    norm_B = np.linalg.norm(B)\n",
    "\n",
    "    if norm_A == 0 or norm_B == 0:\n",
    "        return 0\n",
    "\n",
    "    return dot_product / (norm_A * norm_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "\n",
    "\n",
    "class ItemMemory:\n",
    "    def __init__(self, vectors=[]):\n",
    "        self.vectors = vectors\n",
    "\n",
    "    def addVector(self, label, V):\n",
    "        self.vectors.append((label, V))\n",
    "\n",
    "    def cleanup(self, V):\n",
    "        return max(self.vectors, key=lambda x: cosine_similarity(V, x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic arithemtic operations\n",
    "\n",
    "\n",
    "def weightedAverage(A, B, p, q):\n",
    "    return np.fromiter(\n",
    "        map(lambda t: np.random.choice([t[0], t[1]], p=[p, q]), zip(A, B)),\n",
    "        dtype=np.int_,\n",
    "    )\n",
    "\n",
    "\n",
    "def hdvA(B, a):\n",
    "    return weightedAverage(B, -B, (a + 1) / 2, (1 - a) / 2)\n",
    "\n",
    "\n",
    "def hdvW(B, w):\n",
    "    start = round(w * len(B))\n",
    "    head = B[:start]\n",
    "    tail = B[start:] * -1\n",
    "    return np.concatenate([head, tail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic tests\n",
    "\n",
    "# A, B = hdv(10000), hdv(10000)\n",
    "# C = weightedAverage(A, B, 0.90, 0.1)\n",
    "# # print(A)\n",
    "# # print(B)\n",
    "# # print(C)\n",
    "# # print(cosine_similarity(A, B))\n",
    "# # print(cosine_similarity(B, C))\n",
    "\n",
    "# a = 0.75\n",
    "\n",
    "# Ba = hdvA(B, a)\n",
    "# Bb = hdvA(B, 0.6)\n",
    "# print(cosine_similarity(B, Ba))\n",
    "# # print(cosine_similarity(Ba, Bb))\n",
    "# print((cosine_similarity(B, Ba) + 1) / 2)\n",
    "# print((similarity(B, Ba) + 1) / 2)\n",
    "\n",
    "# Bw = hdvW(B, 0.1)\n",
    "# print(B)\n",
    "# print(Bw)\n",
    "# print(cosine_similarity(B, Bw))\n",
    "# print((cosine_similarity(B, Bw) + 1) / 2)\n",
    "\n",
    "# Bw1 = hdvW(B, 0.0248)\n",
    "# Bw2 = hdvW(B, 0.015)\n",
    "# print(cosine_similarity(Bw1, Bw2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform(graphs, 0.45, 5)[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDataset(dataset):\n",
    "    graphs = []\n",
    "    labels = []\n",
    "\n",
    "    for graph in dataset:\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(zip(graph[\"edge_index\"][0], graph[\"edge_index\"][1]))\n",
    "        graphs.append(G)\n",
    "        labels.append(graph[\"y\"][0])\n",
    "\n",
    "    return (graphs, labels)\n",
    "\n",
    "\n",
    "def transform(X, alpha, digits):\n",
    "    graphs = []\n",
    "    for graph in X:\n",
    "        gpr = nx.pagerank(graph, alpha)\n",
    "        nodes = dict()\n",
    "        for key, value in gpr.items():\n",
    "            nodes[key] = str(round(value, digits))\n",
    "        H = nx.relabel_nodes(graph, nodes)\n",
    "        graphs.append(H)\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def encodeGraph(graph, vertices, dimensions, base):\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            vertices[node] = hdvW(base, float(node))\n",
    "\n",
    "    Edges = []\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        v1 = vertices[edge[0]]\n",
    "        v2 = vertices[edge[1]]\n",
    "        E = bind([v1, v2])\n",
    "        Edges.append(E)\n",
    "\n",
    "    Graph = bundle(Edges)\n",
    "\n",
    "    return Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHD(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, alpha=0.45, digits=4, dimensions=10000, step=20):\n",
    "        self.alpha = alpha\n",
    "        self.digits = digits\n",
    "        self.dimensions = dimensions\n",
    "        self.step = step\n",
    "        self.B = hdv(dimensions)\n",
    "        self.memory = ItemMemory([])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vertices = dict()\n",
    "        self.labels = list(set(y))\n",
    "        dictLabels = dict()\n",
    "\n",
    "        graphs = transform(X, self.alpha, self.digits)\n",
    "\n",
    "        for label in self.labels:\n",
    "            dictLabels[label] = []\n",
    "\n",
    "        for i in range(len(graphs)):\n",
    "            Graph = encodeGraph(graphs[i], self.vertices, self.dimensions, self.B)\n",
    "            dictLabels[y[i]].append(Graph)\n",
    "\n",
    "        for key, value in dictLabels.items():\n",
    "            for i in range(0, len(value), self.step):\n",
    "                H = bundle(value[i : i + self.step])\n",
    "                self.memory.addVector(str(key), H)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        p = []\n",
    "        s = []\n",
    "\n",
    "        graphs = transform(X, self.alpha, self.digits)\n",
    "\n",
    "        for testGraph in graphs:\n",
    "            queryVector = encodeGraph(testGraph, self.vertices, self.dimensions, self.B)\n",
    "            cleanVector = self.memory.cleanup(queryVector)\n",
    "\n",
    "            p.append(int(cleanVector[0]))\n",
    "            # s.append(cosine_similarity(queryVector, cleanVector[1]))\n",
    "\n",
    "        # print(\"%.5f\" % round(np.mean(s), 5), \"0:\", p.count(0), \"1:\", p.count(1))\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUTAG = load_dataset(\"graphs-datasets/MUTAG\")[\"train\"]\n",
    "PROTEINS = load_dataset(\"graphs-datasets/PROTEINS\")[\"train\"]\n",
    "AIDS = load_dataset(\"graphs-datasets/AIDS\")[\"full\"]\n",
    "IMDB = load_dataset(\"graphs-datasets/IMDB-BINARY\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "(graphs, labels) = processDataset(MUTAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0.85029\n",
      "1 -> 0.85029\n",
      "2 -> 0.85029\n",
      "S => 0.85029\n"
     ]
    }
   ],
   "source": [
    "FOLDS, REPS, CV = 10, 3, FOLDS\n",
    "ALPHA, DIGITS, DIMENSIONS, STEP = 0.85, 5, 10000, 20\n",
    "\n",
    "\n",
    "def main():\n",
    "    clf = GraphHD(ALPHA, DIGITS, DIMENSIONS, STEP)\n",
    "    sum = 0\n",
    "    for i in range(REPS):\n",
    "        # CV = ShuffleSplit(n_splits=5, test_size=0.25)  # random_state=0\n",
    "        scores = cross_val_score(clf, graphs, labels, n_jobs=-1, cv=CV, verbose=0)\n",
    "        sum += scores.mean()\n",
    "        print(i, \"->\", \"%.5f\" % scores.mean())\n",
    "        del scores\n",
    "\n",
    "    print(\"S => %.5f\" % (sum / REPS))\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
