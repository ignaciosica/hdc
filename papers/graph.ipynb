{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "import networkx as nx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithemitic operations\n",
    "\n",
    "\n",
    "def hdv(d):\n",
    "    return np.random.choice([-1, 1], d)\n",
    "\n",
    "\n",
    "def bind(xs):\n",
    "    return ft.reduce(lambda x, y: x * y, xs)\n",
    "\n",
    "\n",
    "def bundle(xs):\n",
    "    return ft.reduce(lambda x, y: x + y, xs)\n",
    "\n",
    "\n",
    "def similarity(A, B):\n",
    "    return np.dot(A, B) / len(A)\n",
    "\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_A = np.linalg.norm(A)\n",
    "    norm_B = np.linalg.norm(B)\n",
    "\n",
    "    if norm_A == 0 or norm_B == 0:\n",
    "        return 0\n",
    "\n",
    "    return dot_product / (norm_A * norm_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "\n",
    "\n",
    "class ItemMemory:\n",
    "    def __init__(self, vectors=[]):\n",
    "        self.vectors = vectors\n",
    "\n",
    "    def addVector(self, label, V):\n",
    "        self.vectors.append((label, V))\n",
    "\n",
    "    def cleanup(self, V):\n",
    "        return max(self.vectors, key=lambda x: cosine_similarity(V, x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic arithemtic operations\n",
    "\n",
    "\n",
    "def weightedAverage(A, B, p, q):\n",
    "    return np.fromiter(\n",
    "        map(lambda t: np.random.choice([t[0], t[1]], p=[p, q]), zip(A, B)),\n",
    "        dtype=np.int_,\n",
    "    )\n",
    "\n",
    "\n",
    "def hdvA(B, a):\n",
    "    return weightedAverage(B, -B, (a + 1) / 2, (1 - a) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508\n"
     ]
    }
   ],
   "source": [
    "# Basic tests\n",
    "\n",
    "A, B = hdv(1000), hdv(1000)\n",
    "C = weightedAverage(A, B, 0.90, 0.1)\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(C)\n",
    "# print(cosine_similarity(A, C))\n",
    "# print(cosine_similarity(B, C))\n",
    "\n",
    "Ba = hdvA(B, 0.5)\n",
    "print(cosine_similarity(B, Ba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDataset(dataset):\n",
    "    graphs = []\n",
    "    labels = []\n",
    "\n",
    "    for graph in dataset:\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(zip(graph[\"edge_index\"][0], graph[\"edge_index\"][1]))\n",
    "        graphs.append(G)\n",
    "        labels.append(graph[\"y\"][0])\n",
    "\n",
    "    return (graphs, labels)\n",
    "\n",
    "\n",
    "def transform(X, alpha):\n",
    "    graphs = []\n",
    "    for graph in X:\n",
    "        gpr = nx.pagerank(graph, alpha)\n",
    "        H = nx.relabel_nodes(graph, gpr)\n",
    "        graphs.append(H)\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def encodeGraph(graph, vertices, base):\n",
    "    for node in graph.nodes:\n",
    "        if node not in vertices:\n",
    "            # print(node)\n",
    "            vertices[node] = hdvA(base, node)\n",
    "            # vertices[node] = hdv(10000)\n",
    "\n",
    "    Edges = []\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        v1 = vertices[edge[0]]\n",
    "        v2 = vertices[edge[1]]\n",
    "        E = bind([v1, v2])\n",
    "        Edges.append(E)\n",
    "\n",
    "    Graph = bundle(Edges)\n",
    "\n",
    "    return Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHD(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, alpha=0.45, dimensions=10000, step=20):\n",
    "        self.alpha = alpha\n",
    "        self.step = step\n",
    "        self.dimensions = dimensions\n",
    "        self.base = hdv(dimensions)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.memory = ItemMemory([])\n",
    "        self.vertices = dict()\n",
    "        self.labels = list(set(y))\n",
    "        dictLabels = dict()\n",
    "\n",
    "        graphs = transform(X, self.alpha)\n",
    "\n",
    "        for label in self.labels:\n",
    "            dictLabels[label] = []\n",
    "\n",
    "        for i in range(len(graphs)):\n",
    "            Graph = encodeGraph(graphs[i], self.vertices, self.base)\n",
    "            dictLabels[y[i]].append(Graph)\n",
    "\n",
    "        for key, value in dictLabels.items():\n",
    "            for i in range(0, len(value), self.step):\n",
    "                H = bundle(value[i : i + self.step])\n",
    "                self.memory.addVector(str(key), H)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        p = []\n",
    "        s = []\n",
    "\n",
    "        graphs = transform(X, self.alpha)\n",
    "\n",
    "        for testGraph in graphs:\n",
    "            queryVector = encodeGraph(testGraph, self.vertices, self.base)\n",
    "            cleanVector = self.memory.cleanup(queryVector)\n",
    "\n",
    "            p.append(int(cleanVector[0]))\n",
    "            # s.append(cosine_similarity(queryVector, cleanVector[1]))\n",
    "\n",
    "        # print(\"%.5f\" % round(np.mean(s), 5), \"0:\", p.count(0), \"1:\", p.count(1))\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUTAG = load_dataset(\"graphs-datasets/MUTAG\")\n",
    "# PROTEINS = load_dataset(\"graphs-datasets/PROTEINS\")\n",
    "(graphs, labels) = processDataset(MUTAG[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.368) total time= 4.2min\n",
      "[CV] END ................................ score: (test=0.737) total time= 4.3min\n",
      "[CV] END ................................ score: (test=0.737) total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  4.3min remaining: 10.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.947) total time= 4.3min\n",
      "[CV] END ................................ score: (test=0.737) total time= 4.4min\n",
      "[CV] END ................................ score: (test=0.444) total time= 4.4min\n",
      "[CV] END ................................ score: (test=0.667) total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  4.4min remaining:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.842) total time= 4.4min\n",
      "[CV] END ................................ score: (test=0.737) total time= 4.4min\n",
      "[CV] END ................................ score: (test=0.579) total time= 4.6min\n",
      "0 -> 0.67953\n",
      "S => 0.67953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.6min finished\n"
     ]
    }
   ],
   "source": [
    "FOLDS, REPS = 10, 1\n",
    "\n",
    "# MUTAG\n",
    "ALPHA, DIMENSIONS, STEP = 0.65, 10000, 20\n",
    "\n",
    "# PROTEINS\n",
    "# ALPHA, DIMENSIONS, STEP = 0.65, 10000, 4\n",
    "\n",
    "\n",
    "def main():\n",
    "    clf = GraphHD(ALPHA, DIMENSIONS, STEP)\n",
    "    sum = 0\n",
    "    for i in range(REPS):\n",
    "        scores = cross_val_score(clf, graphs, labels, n_jobs=-1, cv=FOLDS, verbose=3)\n",
    "        sum += scores.mean()\n",
    "        print(i, \"->\", \"%.5f\" % scores.mean())\n",
    "        del scores\n",
    "\n",
    "    print(\"S => %.5f\" % (sum / REPS))\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
