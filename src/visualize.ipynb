{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torchmetrics\n",
    "\n",
    "import torchhd\n",
    "from torchhd import embeddings\n",
    "from torchhd.models import Centroid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_centrality(G):\n",
    "    \"\"\"\n",
    "    Compute the degree centrality for nodes.\n",
    "    \"\"\"\n",
    "    _, columns = G.edge_index\n",
    "    degree = torch.bincount(columns, minlength=G.num_nodes)\n",
    "    return degree / G.num_nodes\n",
    "\n",
    "\n",
    "def to_undirected(edge_index):\n",
    "    \"\"\"\n",
    "    Returns the undirected edge_index\n",
    "    [[0, 1], [1, 0]] will result in [[0], [1]]\n",
    "    \"\"\"\n",
    "    edge_index = edge_index.sort(dim=0)[0]\n",
    "    edge_index = torch.unique(edge_index, dim=1)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def min_max_graph_size(graph_dataset):\n",
    "    if len(graph_dataset) == 0:\n",
    "        return None, None\n",
    "\n",
    "    max_num_nodes = float(\"-inf\")\n",
    "    min_num_nodes = float(\"inf\")\n",
    "\n",
    "    for G in graph_dataset:\n",
    "        num_nodes = G.num_nodes\n",
    "        max_num_nodes = max(max_num_nodes, num_nodes)\n",
    "        min_num_nodes = min(min_num_nodes, num_nodes)\n",
    "\n",
    "    return min_num_nodes, max_num_nodes\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_features, size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.node_ids = embeddings.Random(size, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pr = degree_centrality(x)\n",
    "        _, pr_argsort = pr.sort()\n",
    "\n",
    "        node_id_hvs = torch.zeros((x.num_nodes, self.out_features), device=device)\n",
    "        node_id_hvs[pr_argsort] = self.node_ids.weight[: x.num_nodes]\n",
    "\n",
    "        row, col = to_undirected(x.edge_index)\n",
    "\n",
    "        hvs = torchhd.bind(node_id_hvs[row], node_id_hvs[col])\n",
    "        return torchhd.multiset(hvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MUTAG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 131/131 [00:00<00:00, 977.42it/s]\n",
      "Testing_: 100%|██████████| 57/57 [00:00<00:00, 1073.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: f1-score of 68.421%\n",
      "Time: 0.191s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DIMENSIONS = 10000\n",
    "\n",
    "dataset = \"MUTAG\"\n",
    "print(f\"Testing {dataset}\")\n",
    "\n",
    "graphs = TUDataset(\"../data\", dataset)\n",
    "train_size = int(0.7 * len(graphs))\n",
    "test_size = len(graphs) - train_size\n",
    "\n",
    "train_ld, test_ld = torch.utils.data.random_split(graphs, [train_size, test_size])\n",
    "\n",
    "min_graph_size, max_graph_size = min_max_graph_size(graphs)\n",
    "\n",
    "encoder = Encoder(DIMENSIONS, max_graph_size)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "model = Centroid(DIMENSIONS, graphs.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for samples in tqdm(train_ld, desc=\"Training\"):\n",
    "        samples.edge_index = samples.edge_index.to(device)\n",
    "        samples.y = samples.y.to(device)\n",
    "\n",
    "        test_samples_hv = encoder(samples).unsqueeze(0)\n",
    "        model.add_online(test_samples_hv, samples.y)\n",
    "\n",
    "\n",
    "f1score = torchmetrics.F1Score(\"multiclass\", num_classes=graphs.num_classes)\n",
    "\n",
    "model.normalize()\n",
    "matrix = torch.zeros((len(test_ld), DIMENSIONS))\n",
    "incorrect = torch.zeros((0,), dtype=torch.int)\n",
    "true_labels = torch.zeros((len(test_ld),))\n",
    "\n",
    "\n",
    "for index, samples in enumerate(tqdm(test_ld, desc=\"Testing_\")):\n",
    "    samples.edge_index = samples.edge_index.to(device)\n",
    "\n",
    "    test_samples_hv = encoder(samples).unsqueeze(0)\n",
    "    matrix[index] = test_samples_hv\n",
    "    test_outputs = model(test_samples_hv, dot=True)\n",
    "\n",
    "    true_labels[index] = samples.y.item()\n",
    "\n",
    "    f1score.update(test_outputs.cpu(), samples.y)\n",
    "    if test_outputs.cpu().argmax() != samples.y:\n",
    "        incorrect = torch.cat((incorrect, torch.tensor([index])), 0)\n",
    "        # incorrect_prediction[index] = index\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Test: f1-score of {f1score.compute().item() * 100:.3f}%\")\n",
    "print(f\"Time: {(end - start):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "locally_linear_embedding() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/p4ssenger/Src/hdc/src/visualize.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanifold\u001b[39;00m \u001b[39mimport\u001b[39;00m TSNE, MDS, Isomap,locally_linear_embedding\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42, perplexity=5)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# tsne = MDS(n_components=2, random_state=42)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tsne \u001b[39m=\u001b[39m locally_linear_embedding(n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m vis_dims \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39mfit_transform(matrix)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m colors \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: locally_linear_embedding() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42, perplexity=5)\n",
    "vis_dims = tsne.fit_transform(matrix)\n",
    "colors = [\"blue\", \"green\"]\n",
    "x = np.array([x for x, _ in vis_dims])\n",
    "y = np.array([y for _, y in vis_dims])\n",
    "color_indices = true_labels\n",
    "\n",
    "colormap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "mask = np.ones(len(test_ld), dtype=bool)\n",
    "mask[incorrect] = False\n",
    "\n",
    "plt.scatter(x[mask], y[mask], c=color_indices[mask], cmap=colormap, alpha=0.3)\n",
    "\n",
    "plt.scatter(x[incorrect], y[incorrect], c=color_indices[incorrect], cmap=colormap, alpha=0.6, marker=\"x\")\n",
    "\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p4ssenger/.local/lib/python3.10/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n",
      "Training:   1%|          | 5/779 [00:10<25:52,  2.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/p4ssenger/Src/hdc/src/visualize.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         \u001b[39m# incorrect_prediction[index] = index\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42, perplexity=5)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m tsne \u001b[39m=\u001b[39m MDS(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m vis_dims \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39;49mfit_transform(matrix)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m colors \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/p4ssenger/Src/hdc/src/visualize.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x \u001b[39mfor\u001b[39;00m x, _ \u001b[39min\u001b[39;00m vis_dims])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_mds.py:613\u001b[0m, in \u001b[0;36mMDS.fit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdissimilarity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdissimilarity_matrix_ \u001b[39m=\u001b[39m euclidean_distances(X)\n\u001b[0;32m--> 613\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstress_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m smacof(\n\u001b[1;32m    614\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdissimilarity_matrix_,\n\u001b[1;32m    615\u001b[0m     metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric,\n\u001b[1;32m    616\u001b[0m     n_components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m    617\u001b[0m     init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    618\u001b[0m     n_init\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_init,\n\u001b[1;32m    619\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    620\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    621\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    622\u001b[0m     eps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    623\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m    624\u001b[0m     return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m     normalized_stress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_stress,\n\u001b[1;32m    626\u001b[0m )\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_mds.py:329\u001b[0m, in \u001b[0;36msmacof\u001b[0;34m(dissimilarities, metric, n_components, init, n_init, n_jobs, max_iter, verbose, eps, random_state, return_n_iter, normalized_stress)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_init):\n\u001b[0;32m--> 329\u001b[0m         pos, stress, n_iter_ \u001b[39m=\u001b[39m _smacof_single(\n\u001b[1;32m    330\u001b[0m             dissimilarities,\n\u001b[1;32m    331\u001b[0m             metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    332\u001b[0m             n_components\u001b[39m=\u001b[39;49mn_components,\n\u001b[1;32m    333\u001b[0m             init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    334\u001b[0m             max_iter\u001b[39m=\u001b[39;49mmax_iter,\n\u001b[1;32m    335\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    336\u001b[0m             eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    337\u001b[0m             random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    338\u001b[0m             normalized_stress\u001b[39m=\u001b[39;49mnormalized_stress,\n\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    340\u001b[0m         \u001b[39mif\u001b[39;00m best_stress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m stress \u001b[39m<\u001b[39m best_stress:\n\u001b[1;32m    341\u001b[0m             best_stress \u001b[39m=\u001b[39m stress\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_mds.py:147\u001b[0m, in \u001b[0;36m_smacof_single\u001b[0;34m(dissimilarities, metric, n_components, init, max_iter, verbose, eps, random_state, normalized_stress)\u001b[0m\n\u001b[1;32m    142\u001b[0m     disparities \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(\n\u001b[1;32m    143\u001b[0m         (n_samples \u001b[39m*\u001b[39m (n_samples \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m/\u001b[39m (disparities\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    146\u001b[0m \u001b[39m# Compute stress\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m stress \u001b[39m=\u001b[39m ((dis\u001b[39m.\u001b[39;49mravel() \u001b[39m-\u001b[39;49m disparities\u001b[39m.\u001b[39;49mravel()) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49msum() \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m normalized_stress:\n\u001b[1;32m    149\u001b[0m     stress \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(stress \u001b[39m/\u001b[39m ((disparities\u001b[39m.\u001b[39mravel() \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[39mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "DIMENSIONS = 10000\n",
    "\n",
    "dataset = \"PROTEINS\"\n",
    "# print(f\"Testing {dataset}\")\n",
    "\n",
    "graphs = TUDataset(\"../data\", dataset)\n",
    "train_size = int(0.7 * len(graphs))\n",
    "test_size = len(graphs) - train_size\n",
    "\n",
    "train_ld, test_ld = torch.utils.data.random_split(graphs, [train_size, test_size])\n",
    "\n",
    "min_graph_size, max_graph_size = min_max_graph_size(graphs)\n",
    "\n",
    "encoder = Encoder(DIMENSIONS, max_graph_size)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "model = Centroid(DIMENSIONS, graphs.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for samples in tqdm(train_ld, desc=\"Training\"):\n",
    "        clear_output(wait=True)\n",
    "        samples.edge_index = samples.edge_index.to(device)\n",
    "        samples.y = samples.y.to(device)\n",
    "\n",
    "        test_samples_hv = encoder(samples).unsqueeze(0)\n",
    "        model.add_online(test_samples_hv, samples.y)\n",
    "\n",
    "        ######################################################################################\n",
    "\n",
    "        f1score = torchmetrics.F1Score(\"multiclass\", num_classes=graphs.num_classes)\n",
    "\n",
    "        # model.normalize()\n",
    "        matrix = torch.zeros((len(test_ld), DIMENSIONS))\n",
    "        incorrect = torch.zeros((0,), dtype=torch.int)\n",
    "        true_labels = torch.zeros((len(test_ld),))\n",
    "\n",
    "        for index, samples in enumerate(tqdm(test_ld, desc=\"Testing_\", disable=True)):\n",
    "            samples.edge_index = samples.edge_index.to(device)\n",
    "\n",
    "            test_samples_hv = encoder(samples).unsqueeze(0)\n",
    "            matrix[index] = test_samples_hv\n",
    "            test_outputs = model(test_samples_hv, dot=True)\n",
    "\n",
    "            true_labels[index] = samples.y.item()\n",
    "\n",
    "            f1score.update(test_outputs.cpu(), samples.y)\n",
    "            if test_outputs.cpu().argmax() != samples.y:\n",
    "                incorrect = torch.cat((incorrect, torch.tensor([index])), 0)\n",
    "                # incorrect_prediction[index] = index\n",
    "\n",
    "        # tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42, perplexity=5)\n",
    "        tsne = MDS(n_components=2, random_state=42)\n",
    "        vis_dims = tsne.fit_transform(matrix)\n",
    "        colors = [\"blue\", \"green\"]\n",
    "        x = np.array([x for x, _ in vis_dims])\n",
    "        y = np.array([y for _, y in vis_dims])\n",
    "        color_indices = true_labels\n",
    "\n",
    "        colormap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "        mask = np.ones(len(test_ld), dtype=bool)\n",
    "        mask[incorrect] = False\n",
    "\n",
    "        plt.scatter(x[mask], y[mask], c=color_indices[mask], cmap=colormap, alpha=0.3)\n",
    "\n",
    "        plt.scatter(x[incorrect], y[incorrect], c=color_indices[incorrect], cmap=colormap, alpha=0.6, marker=\"x\")\n",
    "\n",
    "        plt.show()\n",
    "        print(f\"Test: f1-score of {f1score.compute().item() * 100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
